---------- Begin SLURM Prolog ----------
Job ID:        7208149
Username:      siliangc
Accountname:   lc_fs3
Name:          batchrun_lstm.sh
Partition:     main
Nodelist:      hpc4672
TasksPerNode:  1
CPUsPerTask:   Default[1]
TMPDIR:        /tmp/7208149.main
SCRATCHDIR:    /staging/scratch/7208149
Cluster:       uschpc
HSDA Account:  false
---------- 2020-05-05 14:45:32 ---------
2020-05-05 14:58:08.772830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-05 14:58:08.930250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-05 14:58:08.937528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-05 14:58:08.951762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-05 14:58:09.375429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-05 14:58:09.666424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-05 14:58:10.070607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-05 14:58:10.535872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-05 14:58:10.673870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-05 14:58:11.150089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-05 14:58:11.161544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-05-05 14:58:11.166473: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-05 14:58:11.473489: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
2020-05-05 14:58:11.477890: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8201722e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-05 14:58:11.477957: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-05 14:58:11.989064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8201dc4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-05 14:58:11.989144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2020-05-05 14:58:11.989173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-32GB, Compute Capability 7.0
2020-05-05 14:58:12.110411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-05 14:58:12.112700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-05 14:58:12.112782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-05 14:58:12.112806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-05 14:58:12.112833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-05 14:58:12.112854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-05 14:58:12.112875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-05 14:58:12.112895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-05 14:58:12.112916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-05 14:58:12.119990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-05-05 14:58:12.120045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-05 14:58:12.123153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-05 14:58:12.123175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 
2020-05-05 14:58:12.123184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y 
2020-05-05 14:58:12.123190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N 
2020-05-05 14:58:12.128245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30233 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
2020-05-05 14:58:12.130226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30233 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)
2020-05-05 14:58:32.589209: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14599008000 exceeds 10% of free system memory.
2020-05-05 14:59:06.840016: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14599008000 exceeds 10% of free system memory.
2020-05-05 14:59:19.899346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-05 14:59:20.773485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Processing Data...
Processing sequences of length: 3kk

Processing forward host data...
Processing prokaryote training data from ProkTr#ProkTr#3k_num1_seq66847_codefw.npy
Processing eukaryote training data from EukTr#EukTr#3k_num1_seq65382_codefw.npy
Processing reverse host data...
Processing prokaryote training data from ProkTr#ProkTr#3k_num1_seq66847_codebw.npy
Processing eukaryote training data from EukTr#EukTr#3k_num1_seq65382_codebw.npy
Processing plasmid data
Processing plasmid data - bw
Processing virus data...
Processing prokaryotevirus training data from ProkVirusTr#ProkVirusTr#3k_num1_seq66765_codefw.npy
Processin eukaryotevirus training data from EukVirusTr#EukVirusTr#3k_num1_seq34669_codefw.npy
Processing virus data...
Processing prokaryotevirus training data from ProkVirusTr#ProkVirusTr#3k_num1_seq66765_codebw.npy
Processin eukaryotevirus training data from EukVirusTr#EukVirusTr#3k_num1_seq34669_codebw.npy
Processing Validation Data...
Processing Validation Data - bw...
(304146, 3000, 4)
(304146, 3000, 4)
(304146, 5)
(32442, 3000, 4)
(32442, 3000, 4)
(32442, 5)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, None, 4)]    0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, None, 4)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, None, 64)     1600        input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, None, 64)     0           conv1d[0][0]                     
                                                                 conv1d[1][0]                     
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, None, 128)    24704       max_pooling1d[0][0]              
                                                                 max_pooling1d[1][0]              
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   
                                                                 conv1d_1[1][0]                   
__________________________________________________________________________________________________
bidirectional (Bidirectional)   (None, 128)          98816       max_pooling1d_1[0][0]            
                                                                 max_pooling1d_1[1][0]            
__________________________________________________________________________________________________
dropout (Dropout)               (None, 128)          0           bidirectional[0][0]              
                                                                 bidirectional[1][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 500)          64500       dropout[0][0]                    
                                                                 dropout[1][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 500)          0           dense[0][0]                      
                                                                 dense[1][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 5)            2505        dropout_1[0][0]                  
                                                                 dropout_1[1][0]                  
__________________________________________________________________________________________________
average (Average)               (None, 5)            0           dense_1[0][0]                    
                                                                 dense_1[1][0]                    
==================================================================================================
Total params: 192,125
Trainable params: 192,125
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/60

Epoch 00001: val_loss improved from inf to 1.51591, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 519s - loss: 1.5223 - accuracy: 0.2902 - val_loss: 1.5159 - val_accuracy: 0.2668
Epoch 2/60

Epoch 00002: val_loss did not improve from 1.51591
3042/3042 - 521s - loss: 1.4832 - accuracy: 0.3187 - val_loss: 1.5531 - val_accuracy: 0.2478
Epoch 3/60

Epoch 00003: val_loss improved from 1.51591 to 1.09251, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 519s - loss: 1.2689 - accuracy: 0.4159 - val_loss: 1.0925 - val_accuracy: 0.4889
Epoch 4/60

Epoch 00004: val_loss improved from 1.09251 to 1.03693, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 518s - loss: 1.0188 - accuracy: 0.5377 - val_loss: 1.0369 - val_accuracy: 0.6230
Epoch 5/60

Epoch 00005: val_loss improved from 1.03693 to 0.88999, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 522s - loss: 0.8329 - accuracy: 0.6441 - val_loss: 0.8900 - val_accuracy: 0.6702
Epoch 6/60

Epoch 00006: val_loss improved from 0.88999 to 0.76627, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 522s - loss: 0.7252 - accuracy: 0.7008 - val_loss: 0.7663 - val_accuracy: 0.6900
Epoch 7/60

Epoch 00007: val_loss did not improve from 0.76627
3042/3042 - 520s - loss: 0.6581 - accuracy: 0.7357 - val_loss: 0.7940 - val_accuracy: 0.7193
Epoch 8/60

Epoch 00008: val_loss improved from 0.76627 to 0.68708, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 522s - loss: 0.6096 - accuracy: 0.7586 - val_loss: 0.6871 - val_accuracy: 0.7560
Epoch 9/60

Epoch 00009: val_loss improved from 0.68708 to 0.67637, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 521s - loss: 0.5758 - accuracy: 0.7739 - val_loss: 0.6764 - val_accuracy: 0.7448
Epoch 10/60

Epoch 00010: val_loss improved from 0.67637 to 0.61250, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 522s - loss: 0.5460 - accuracy: 0.7872 - val_loss: 0.6125 - val_accuracy: 0.7803
Epoch 11/60

Epoch 00011: val_loss improved from 0.61250 to 0.58309, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 520s - loss: 0.5178 - accuracy: 0.8004 - val_loss: 0.5831 - val_accuracy: 0.7927
Epoch 12/60

Epoch 00012: val_loss improved from 0.58309 to 0.53777, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 519s - loss: 0.4937 - accuracy: 0.8112 - val_loss: 0.5378 - val_accuracy: 0.7923
Epoch 13/60

Epoch 00013: val_loss did not improve from 0.53777
3042/3042 - 520s - loss: 0.4701 - accuracy: 0.8225 - val_loss: 0.6359 - val_accuracy: 0.7679
Epoch 14/60

Epoch 00014: val_loss did not improve from 0.53777
3042/3042 - 515s - loss: 0.4733 - accuracy: 0.8217 - val_loss: 0.5483 - val_accuracy: 0.7857
Epoch 15/60

Epoch 00015: val_loss did not improve from 0.53777
3042/3042 - 520s - loss: 0.4368 - accuracy: 0.8370 - val_loss: 0.5659 - val_accuracy: 0.7901
Epoch 16/60

Epoch 00016: val_loss did not improve from 0.53777
3042/3042 - 521s - loss: 0.4142 - accuracy: 0.8469 - val_loss: 0.6310 - val_accuracy: 0.7880
Epoch 17/60

Epoch 00017: val_loss improved from 0.53777 to 0.48876, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 524s - loss: 0.3992 - accuracy: 0.8531 - val_loss: 0.4888 - val_accuracy: 0.8211
Epoch 18/60

Epoch 00018: val_loss did not improve from 0.48876
3042/3042 - 524s - loss: 0.3845 - accuracy: 0.8583 - val_loss: 0.5614 - val_accuracy: 0.8090
Epoch 19/60

Epoch 00019: val_loss did not improve from 0.48876
3042/3042 - 523s - loss: 0.3718 - accuracy: 0.8644 - val_loss: 0.5847 - val_accuracy: 0.8066
Epoch 20/60

Epoch 00020: val_loss improved from 0.48876 to 0.48114, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 519s - loss: 0.3581 - accuracy: 0.8690 - val_loss: 0.4811 - val_accuracy: 0.8234
Epoch 21/60

Epoch 00021: val_loss did not improve from 0.48114
3042/3042 - 520s - loss: 0.3511 - accuracy: 0.8717 - val_loss: 0.5463 - val_accuracy: 0.8139
Epoch 22/60

Epoch 00022: val_loss did not improve from 0.48114
3042/3042 - 520s - loss: 0.3395 - accuracy: 0.8758 - val_loss: 0.5739 - val_accuracy: 0.8184
Epoch 23/60

Epoch 00023: val_loss did not improve from 0.48114
3042/3042 - 520s - loss: 0.3367 - accuracy: 0.8771 - val_loss: 0.5401 - val_accuracy: 0.8116
Epoch 24/60

Epoch 00024: val_loss did not improve from 0.48114
3042/3042 - 521s - loss: 0.3255 - accuracy: 0.8816 - val_loss: 0.4859 - val_accuracy: 0.8184
Epoch 25/60

Epoch 00025: val_loss improved from 0.48114 to 0.46267, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 521s - loss: 0.3193 - accuracy: 0.8843 - val_loss: 0.4627 - val_accuracy: 0.8369
Epoch 26/60

Epoch 00026: val_loss did not improve from 0.46267
3042/3042 - 522s - loss: 0.3104 - accuracy: 0.8877 - val_loss: 0.5296 - val_accuracy: 0.8251
Epoch 27/60

Epoch 00027: val_loss improved from 0.46267 to 0.44277, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 524s - loss: 0.3035 - accuracy: 0.8900 - val_loss: 0.4428 - val_accuracy: 0.8405
Epoch 28/60

Epoch 00028: val_loss did not improve from 0.44277
3042/3042 - 520s - loss: 0.2995 - accuracy: 0.8918 - val_loss: 0.5128 - val_accuracy: 0.8305
Epoch 29/60

Epoch 00029: val_loss did not improve from 0.44277
3042/3042 - 519s - loss: 0.2894 - accuracy: 0.8947 - val_loss: 0.4615 - val_accuracy: 0.8408
Epoch 30/60

Epoch 00030: val_loss did not improve from 0.44277
3042/3042 - 522s - loss: 0.2848 - accuracy: 0.8970 - val_loss: 0.5199 - val_accuracy: 0.8395
Epoch 31/60

Epoch 00031: val_loss did not improve from 0.44277
3042/3042 - 518s - loss: 0.2811 - accuracy: 0.8977 - val_loss: 0.4701 - val_accuracy: 0.8412
Epoch 32/60

Epoch 00032: val_loss did not improve from 0.44277
3042/3042 - 520s - loss: 0.2761 - accuracy: 0.9001 - val_loss: 0.5204 - val_accuracy: 0.8271
Epoch 33/60

Epoch 00033: val_loss did not improve from 0.44277
3042/3042 - 520s - loss: 0.2722 - accuracy: 0.9015 - val_loss: 0.5485 - val_accuracy: 0.8366
Epoch 34/60

Epoch 00034: val_loss did not improve from 0.44277
3042/3042 - 521s - loss: 0.2714 - accuracy: 0.9015 - val_loss: 0.5258 - val_accuracy: 0.8411
Epoch 35/60

Epoch 00035: val_loss did not improve from 0.44277
3042/3042 - 522s - loss: 0.2655 - accuracy: 0.9043 - val_loss: 0.4503 - val_accuracy: 0.8475
Epoch 36/60

Epoch 00036: val_loss did not improve from 0.44277
3042/3042 - 523s - loss: 0.2595 - accuracy: 0.9057 - val_loss: 0.4888 - val_accuracy: 0.8391
Epoch 37/60

Epoch 00037: val_loss did not improve from 0.44277
3042/3042 - 519s - loss: 0.2534 - accuracy: 0.9078 - val_loss: 0.5811 - val_accuracy: 0.8245
Epoch 38/60

Epoch 00038: val_loss did not improve from 0.44277
3042/3042 - 521s - loss: 0.2494 - accuracy: 0.9092 - val_loss: 0.5357 - val_accuracy: 0.8353
Epoch 39/60

Epoch 00039: val_loss did not improve from 0.44277
3042/3042 - 520s - loss: 0.2505 - accuracy: 0.9087 - val_loss: 0.5537 - val_accuracy: 0.8312
Epoch 40/60

Epoch 00040: val_loss did not improve from 0.44277
3042/3042 - 521s - loss: 0.2465 - accuracy: 0.9102 - val_loss: 0.5882 - val_accuracy: 0.8319
Epoch 41/60

Epoch 00041: val_loss did not improve from 0.44277
3042/3042 - 519s - loss: 0.2415 - accuracy: 0.9123 - val_loss: 0.5267 - val_accuracy: 0.8420
Epoch 42/60

Epoch 00042: val_loss did not improve from 0.44277
3042/3042 - 523s - loss: 0.2392 - accuracy: 0.9130 - val_loss: 0.4822 - val_accuracy: 0.8429
Epoch 43/60

Epoch 00043: val_loss did not improve from 0.44277
3042/3042 - 524s - loss: 0.2367 - accuracy: 0.9139 - val_loss: 0.5215 - val_accuracy: 0.8354
Epoch 44/60

Epoch 00044: val_loss did not improve from 0.44277
3042/3042 - 526s - loss: 0.2324 - accuracy: 0.9154 - val_loss: 0.5225 - val_accuracy: 0.8451
Epoch 45/60

Epoch 00045: val_loss did not improve from 0.44277
3042/3042 - 521s - loss: 0.2299 - accuracy: 0.9164 - val_loss: 0.5765 - val_accuracy: 0.8363
Epoch 00045: early stopping
