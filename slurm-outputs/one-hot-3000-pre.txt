---------- Begin SLURM Prolog ----------
Job ID:        7163990
Username:      siliangc
Accountname:   lc_fs3
Name:          batchrun.sh
Partition:     main
Nodelist:      hpc4626
TasksPerNode:  1
CPUsPerTask:   Default[1]
TMPDIR:        /tmp/7163990.main
SCRATCHDIR:    /staging/scratch/7163990
Cluster:       uschpc
HSDA Account:  false
---------- 2020-05-04 23:34:19 ---------
2020-05-04 23:47:15.427290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-04 23:47:15.574164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-04 23:47:15.577338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-04 23:47:16.103135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-04 23:47:32.914096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-04 23:47:37.766630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-04 23:47:50.868600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-04 23:48:01.400950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-04 23:48:06.106841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-04 23:48:22.869834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-04 23:48:22.885646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-05-04 23:48:22.906088: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-04 23:48:23.294908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
2020-05-04 23:48:23.299398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560754843870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-04 23:48:23.299464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-04 23:48:23.756324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5607548ada20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-04 23:48:23.756402: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2020-05-04 23:48:23.756429: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-32GB, Compute Capability 7.0
2020-05-04 23:48:23.806420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-04 23:48:23.808463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-04 23:48:23.808533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-04 23:48:23.808556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-04 23:48:23.808580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-04 23:48:23.808600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-04 23:48:23.808618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-04 23:48:23.808636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-04 23:48:23.808655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-04 23:48:23.816397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-05-04 23:48:23.816443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-04 23:48:23.823411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-04 23:48:23.823431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 
2020-05-04 23:48:23.823440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y 
2020-05-04 23:48:23.823445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N 
2020-05-04 23:48:23.828341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30233 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
2020-05-04 23:48:23.830728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30233 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)
2020-05-04 23:48:44.040093: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14599008000 exceeds 10% of free system memory.
2020-05-04 23:49:22.655441: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14599008000 exceeds 10% of free system memory.
2020-05-04 23:49:46.732030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-04 23:50:06.162824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Processing Data...
Processing sequences of length: 3kk

Processing forward host data...
Processing prokaryote training data from ProkTr#ProkTr#3k_num1_seq66847_codefw.npy
Processing eukaryote training data from EukTr#EukTr#3k_num1_seq65382_codefw.npy
Processing reverse host data...
Processing prokaryote training data from ProkTr#ProkTr#3k_num1_seq66847_codebw.npy
Processing eukaryote training data from EukTr#EukTr#3k_num1_seq65382_codebw.npy
Processing plasmid data
Processing plasmid data - bw
Processing virus data...
Processing prokaryotevirus training data from ProkVirusTr#ProkVirusTr#3k_num1_seq66765_codefw.npy
Processin eukaryotevirus training data from EukVirusTr#EukVirusTr#3k_num1_seq34669_codefw.npy
Processing virus data...
Processing prokaryotevirus training data from ProkVirusTr#ProkVirusTr#3k_num1_seq66765_codebw.npy
Processin eukaryotevirus training data from EukVirusTr#EukVirusTr#3k_num1_seq34669_codebw.npy
Processing Validation Data...
Processing Validation Data - bw...
(304146, 3000, 4)
(304146, 3000, 4)
(304146, 5)
(32336, 3000, 4)
(32336, 3000, 4)
(32336, 5)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, None, 4)]    0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, None, 4)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, None, 64)     1600        input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, None, 64)     0           conv1d[0][0]                     
                                                                 conv1d[1][0]                     
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, None, 64)     256         max_pooling1d[0][0]              
                                                                 max_pooling1d[1][0]              
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, None, 128)    24704       batch_normalization[0][0]        
                                                                 batch_normalization[1][0]        
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   
                                                                 conv1d_1[1][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, None, 128)    512         max_pooling1d_1[0][0]            
                                                                 max_pooling1d_1[1][0]            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, None, 256)    65792       batch_normalization_1[0][0]      
                                                                 batch_normalization_1[1][0]      
__________________________________________________________________________________________________
global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_2[0][0]                   
                                                                 conv1d_2[1][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 256)          0           global_max_pooling1d[0][0]       
                                                                 global_max_pooling1d[1][0]       
__________________________________________________________________________________________________
flatten (Flatten)               (None, 256)          0           dropout[0][0]                    
                                                                 dropout[1][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 500)          128500      flatten[0][0]                    
                                                                 flatten[1][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 500)          0           dense[0][0]                      
                                                                 dense[1][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 5)            2505        dropout_1[0][0]                  
                                                                 dropout_1[1][0]                  
__________________________________________________________________________________________________
average (Average)               (None, 5)            0           dense_1[0][0]                    
                                                                 dense_1[1][0]                    
==================================================================================================
Total params: 223,869
Trainable params: 223,485
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 1/60

Epoch 00001: val_loss improved from inf to 0.59619, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 177s - loss: 0.8891 - accuracy: 0.6303 - val_loss: 0.5962 - val_accuracy: 0.7841
Epoch 2/60

Epoch 00002: val_loss improved from 0.59619 to 0.52596, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 171s - loss: 0.5993 - accuracy: 0.7654 - val_loss: 0.5260 - val_accuracy: 0.8122
Epoch 3/60

Epoch 00003: val_loss did not improve from 0.52596
3042/3042 - 168s - loss: 0.5186 - accuracy: 0.8029 - val_loss: 0.5425 - val_accuracy: 0.7981
Epoch 4/60

Epoch 00004: val_loss improved from 0.52596 to 0.44143, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 169s - loss: 0.4764 - accuracy: 0.8220 - val_loss: 0.4414 - val_accuracy: 0.8450
Epoch 5/60

Epoch 00005: val_loss did not improve from 0.44143
3042/3042 - 170s - loss: 0.4464 - accuracy: 0.8342 - val_loss: 0.4520 - val_accuracy: 0.8424
Epoch 6/60

Epoch 00006: val_loss improved from 0.44143 to 0.41657, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 170s - loss: 0.4264 - accuracy: 0.8428 - val_loss: 0.4166 - val_accuracy: 0.8548
Epoch 7/60

Epoch 00007: val_loss did not improve from 0.41657
3042/3042 - 171s - loss: 0.4093 - accuracy: 0.8493 - val_loss: 0.4168 - val_accuracy: 0.8534
Epoch 8/60

Epoch 00008: val_loss did not improve from 0.41657
3042/3042 - 168s - loss: 0.3963 - accuracy: 0.8554 - val_loss: 0.4385 - val_accuracy: 0.8493
Epoch 9/60

Epoch 00009: val_loss did not improve from 0.41657
3042/3042 - 168s - loss: 0.3845 - accuracy: 0.8600 - val_loss: 0.4315 - val_accuracy: 0.8509
Epoch 10/60

Epoch 00010: val_loss did not improve from 0.41657
3042/3042 - 170s - loss: 0.3730 - accuracy: 0.8644 - val_loss: 0.4223 - val_accuracy: 0.8517
Epoch 11/60

Epoch 00011: val_loss improved from 0.41657 to 0.40377, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 171s - loss: 0.3670 - accuracy: 0.8671 - val_loss: 0.4038 - val_accuracy: 0.8680
Epoch 12/60

Epoch 00012: val_loss improved from 0.40377 to 0.38026, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 170s - loss: 0.3562 - accuracy: 0.8710 - val_loss: 0.3803 - val_accuracy: 0.8752
Epoch 13/60

Epoch 00013: val_loss did not improve from 0.38026
3042/3042 - 170s - loss: 0.3495 - accuracy: 0.8739 - val_loss: 0.3844 - val_accuracy: 0.8758
Epoch 14/60

Epoch 00014: val_loss did not improve from 0.38026
3042/3042 - 170s - loss: 0.3436 - accuracy: 0.8767 - val_loss: 0.3980 - val_accuracy: 0.8752
Epoch 15/60

Epoch 00015: val_loss did not improve from 0.38026
3042/3042 - 172s - loss: 0.3366 - accuracy: 0.8790 - val_loss: 0.3860 - val_accuracy: 0.8768
Epoch 16/60

Epoch 00016: val_loss did not improve from 0.38026
3042/3042 - 174s - loss: 0.3310 - accuracy: 0.8819 - val_loss: 0.4163 - val_accuracy: 0.8644
Epoch 17/60

Epoch 00017: val_loss did not improve from 0.38026
3042/3042 - 169s - loss: 0.3255 - accuracy: 0.8834 - val_loss: 0.3814 - val_accuracy: 0.8788
Epoch 18/60

Epoch 00018: val_loss improved from 0.38026 to 0.36417, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 170s - loss: 0.3216 - accuracy: 0.8849 - val_loss: 0.3642 - val_accuracy: 0.8848
Epoch 19/60

Epoch 00019: val_loss did not improve from 0.36417
3042/3042 - 171s - loss: 0.3177 - accuracy: 0.8866 - val_loss: 0.3950 - val_accuracy: 0.8698
Epoch 20/60

Epoch 00020: val_loss did not improve from 0.36417
3042/3042 - 169s - loss: 0.3135 - accuracy: 0.8885 - val_loss: 0.3979 - val_accuracy: 0.8784
Epoch 21/60

Epoch 00021: val_loss did not improve from 0.36417
3042/3042 - 170s - loss: 0.3083 - accuracy: 0.8900 - val_loss: 0.3991 - val_accuracy: 0.8755
Epoch 22/60

Epoch 00022: val_loss did not improve from 0.36417
3042/3042 - 171s - loss: 0.3041 - accuracy: 0.8919 - val_loss: 0.3779 - val_accuracy: 0.8851
Epoch 23/60

Epoch 00023: val_loss improved from 0.36417 to 0.35148, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 171s - loss: 0.3016 - accuracy: 0.8927 - val_loss: 0.3515 - val_accuracy: 0.8905
Epoch 24/60

Epoch 00024: val_loss did not improve from 0.35148
3042/3042 - 173s - loss: 0.2988 - accuracy: 0.8950 - val_loss: 0.3661 - val_accuracy: 0.8877
Epoch 25/60

Epoch 00025: val_loss improved from 0.35148 to 0.34729, saving model to ./models/model_DNA_one-hot.h5
3042/3042 - 170s - loss: 0.2953 - accuracy: 0.8950 - val_loss: 0.3473 - val_accuracy: 0.8913
Epoch 26/60

Epoch 00026: val_loss did not improve from 0.34729
3042/3042 - 168s - loss: 0.2921 - accuracy: 0.8968 - val_loss: 0.3761 - val_accuracy: 0.8855
Epoch 27/60

Epoch 00027: val_loss did not improve from 0.34729
3042/3042 - 169s - loss: 0.2879 - accuracy: 0.8987 - val_loss: 0.3679 - val_accuracy: 0.8889
Epoch 28/60

Epoch 00028: val_loss did not improve from 0.34729
3042/3042 - 167s - loss: 0.2855 - accuracy: 0.8992 - val_loss: 0.3609 - val_accuracy: 0.8913
Epoch 29/60

Epoch 00029: val_loss did not improve from 0.34729
3042/3042 - 169s - loss: 0.2824 - accuracy: 0.9000 - val_loss: 0.3945 - val_accuracy: 0.8813
Epoch 30/60

Epoch 00030: val_loss did not improve from 0.34729
3042/3042 - 170s - loss: 0.2812 - accuracy: 0.9007 - val_loss: 0.3670 - val_accuracy: 0.8927
Epoch 31/60

Epoch 00031: val_loss did not improve from 0.34729
3042/3042 - 171s - loss: 0.2779 - accuracy: 0.9020 - val_loss: 0.3768 - val_accuracy: 0.8868
Epoch 32/60

Epoch 00032: val_loss did not improve from 0.34729
3042/3042 - 171s - loss: 0.2758 - accuracy: 0.9031 - val_loss: 0.3621 - val_accuracy: 0.8897
Epoch 33/60

Epoch 00033: val_loss did not improve from 0.34729
3042/3042 - 172s - loss: 0.2744 - accuracy: 0.9044 - val_loss: 0.3950 - val_accuracy: 0.8840
Epoch 34/60

Epoch 00034: val_loss did not improve from 0.34729
3042/3042 - 170s - loss: 0.2703 - accuracy: 0.9048 - val_loss: 0.3688 - val_accuracy: 0.8884
Epoch 35/60

Epoch 00035: val_loss did not improve from 0.34729
3042/3042 - 169s - loss: 0.2680 - accuracy: 0.9053 - val_loss: 0.3788 - val_accuracy: 0.8881
Epoch 36/60

Epoch 00036: val_loss did not improve from 0.34729
3042/3042 - 170s - loss: 0.2664 - accuracy: 0.9056 - val_loss: 0.3616 - val_accuracy: 0.8896
Epoch 37/60

Epoch 00037: val_loss did not improve from 0.34729
3042/3042 - 174s - loss: 0.2641 - accuracy: 0.9074 - val_loss: 0.3816 - val_accuracy: 0.8863
Epoch 38/60

Epoch 00038: val_loss did not improve from 0.34729
3042/3042 - 169s - loss: 0.2638 - accuracy: 0.9081 - val_loss: 0.3725 - val_accuracy: 0.8889
Epoch 39/60

Epoch 00039: val_loss did not improve from 0.34729
3042/3042 - 170s - loss: 0.2614 - accuracy: 0.9088 - val_loss: 0.3779 - val_accuracy: 0.8907
Epoch 40/60

Epoch 00040: val_loss did not improve from 0.34729
3042/3042 - 170s - loss: 0.2584 - accuracy: 0.9096 - val_loss: 0.3713 - val_accuracy: 0.8919
Epoch 00040: early stopping
